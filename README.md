# ğŸŒ¾ Reinforcement Learning-Based Smart Crop Irrigation System

This repository presents an academic project focused on designing and evaluating a smart irrigation system using reinforcement learning. The goal is to develop agents capable of learning optimal water distribution strategies across a growing season while adapting to soil moisture, crop needs, and environmental dynamics. 

---

## ğŸ¯ Objective

The central objective of this project is to reduce water wastage and maximize crop health using intelligent irrigation scheduling. Overirrigation can degrade soil and lower yields, while underwatering causes plant stress. Our RL agents are trained to balance moisture levels to maintain crop health and achieve optimal growth without excess water use.

---

## ğŸŒ± Environment Overview

We created a custom OpenAI Gym-compatible environment that simulates a complete crop growing season (120 days). The crop lifecycle is divided into 3 stages:

1. **Seedling**
2. **Vegetative**
3. **Mature**

At each timestep (day), the agent chooses one of 11 irrigation levels. The state includes:

- **Soil Moisture**: Normalized between 0 and 1
- **Crop Water Loss Rate**
- **Crop Coefficient**: Represents water demand
- **Leaf Area Index (LAI)**: Crop density
- **Growth Stage**: Progress in the 120-day cycle
- **Previous Irrigation Level**
- **Day Number**

---

## ğŸ§  Reward Mechanism

Rewards are based on multiple real-world agricultural factors:

- âœ… **Positive Rewards**:
  - Soil moisture within [0.6, 0.9]
  - Healthy crop growth
  - Minimal water waste

- âŒ **Negative Penalties**:
  - Moisture < 0.6 or > 0.9
  - Excessive irrigation
  - Stressed crops due to under/overwatering
  - Extreme temperature penalties (outside 5Â°Câ€“35Â°C)

Crops are marked "stressed" if optimal conditions are not maintained for >70% of any growth stage.

---

## ğŸ§ª Algorithms Implemented

### ğŸ”¹ DQN (Deep Q-Network)
- Learns Q-values through experience replay
- Epsilon-greedy exploration
- Neural network approximates value function

### ğŸ”¹ A2C (Advantage Actor-Critic)
- Parallel actor-learners
- Generalized Advantage Estimation (GAE)
- Entropy-based exploration encouragement

### ğŸ”¹ PPO (Proximal Policy Optimization)
- Policy gradient method with clipped loss
- Optimizes reward while avoiding drastic policy shifts
- Fast convergence and stable learning

---

## ğŸ“Š Training & Evaluation

### PPO Agent
- Timesteps: 1,000,000  
- ![PPO](media/ppo_sb3_1000000_rewards.png)

### DQN Agent
- ![Training](media/training_rewards.png)
- ![Epsilon Decay](media/epsilon_decay.png)
- ![Eval Avg](media/eval_average_reward.png)
- ![Eval Bars](media/eval_rewards_per_episode.png)

### A2C Agent
- ![Training](media/a2c_logs_1000000_rewards.png)
- ![Eval Avg](media/a2c_average_reward.png)
- ![Eval Bars](media/a2c_rewards_per_episode.png)

---

## ğŸŒ¾ Crop Growth Visualization

| Stage      | Image                        |
|------------|------------------------------|
| Seedling   | ![](media/seedling.png)      |
| Vegetative | ![](media/vegetative.png)    |
| Stressed   | ![](media/stressed.png)      |
| Mature     | ![](media/mature.png)        |

---

## ğŸ¥ Simulation Demos

- [Healthy Crop Growth](media/Crop_with_perfect_growth.mp4)
- [Stressed Crop Scenario](media/Crop_with_stressed_stage.mp4)

---

## ğŸ“ Folder Structure

```
RL-Crop-Irrigation/
â”œâ”€â”€ models/            # Trained agent checkpoints
â”œâ”€â”€ media/             # Reward plots, crop stage visuals, videos
â”œâ”€â”€ logs/              # Training metrics (monitor.csv)
â”œâ”€â”€ notebook/          # Training pipeline and evaluation code
â”œâ”€â”€ docs/              # Final academic report (PDF)
â”œâ”€â”€ requirements.txt   # Environment dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“¦ Setup Instructions

```bash
git clone https://github.com/your-username/RL-Crop-Irrigation.git
cd RL-Crop-Irrigation

# (Optional) Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“˜ References

- APSIM Weather Simulation: https://www.apsim.info  
- Crop-Gym Environment: https://github.com/WUR-AI/crop-gym  
- Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3  
- PPO Algorithm: https://arxiv.org/pdf/1707.06347.pdf

---

## ğŸ‘¨â€ğŸ« Academic Context

This project was developed as part of an advanced AI coursework assignment at the University at Buffalo. It demonstrates real-world application of reinforcement learning to sustainable agriculture. The simulation approximates real environmental challenges and promotes research in data-driven farming strategies.

**Report**: [`docs/mkakarla_pdoma_uditbrah_final_project.pdf`](docs/mkakarla_pdoma_uditbrah_final_project.pdf)

---

## ğŸ‘¨â€ğŸ’» Contributors

- **Aravind Aripaka** â€“ Reinforcement Learning implementation, evaluation, and reporting  
- **Team** â€“ Simulation modeling, training integration, and analysis

---

## ğŸ“„ License

This project is released for academic and research use only.
